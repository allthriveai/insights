---
title: "Winning 1st Place at the MCP - AI Agents Hackathon: Building Pitch Scoop"
author: "Allie Jones"
date: "2025-09-19"
categories: ["AI", "Hackathon", "FastAPI", "Redis", "Awards"]
featured_image: "/images/insights/pitchscoop.png"
youtube_video: ""
excerpt: "How our team won 1st place and Best Use Case of Redis at the MCP - AI Agents Hackathon with Pitch Scoop, an AI-powered pitch competition platform built with FastAPI, Redis, and MCP."
featured_on_homepage: true
priority: 4
draft: false
featured_link: "https://github.com/allthriveai/pitchscoop"
profile_contributors: ["Gina Levy", "Sarah Graup"]
---
# Building with MCP + Redis Stack: Lessons from the AI Agents Hackathon

*Technical learnings from PitchScoop: An MCP-first pitch competition*

## The Challenge
One day at the [MCP - AI Agents Hackathon](https://juniper-giant-a3f.notion.site/MCP-AI-Agents-Hackathon-Sep-19-11c9fb250b4b80c488b7e2d7b6d6816d) in San Francisco (Sep 19). 
**Goal: Explore MCP for AI integration and try Redis Stack for rapid development.**

```sidebyside

We built **PitchScoop**, a pitch competition platform powered by MCP where AI agents manage events, score presentations, and update leaderboards. 

From the start, we challenged ourselves to run every part of the app through MCP. The hackathon ran from 9:30 AM to 4:30 PM, giving us about seven hours of focused development time.

PitchScoop went on to win **first place** as well as **Best Use Case of Redis**. Hereâ€™s what we learned about combining MCP with Redis Stack for rapid prototyping.
---
![mcp-hackathon-first-place](/images/insights/pitchscoop.png)
```

```highlight
## What is MCP? 
**Model Context Protocol (MCP)** is a standard that allows AI agents to call your application's functions directly. Instead of writing custom chatbot code that makes HTTP requests, you can expose your business logic as reusable tools that any AI agent can understand and use.

### How MCPs compare to a traditional APIs
With a traditional API, anyone who wants to integrate with your app has to write the client logic themselves. That usually means handling authentication, formatting requests, parsing responses, and managing errors. By exposing your functions through MCP, you provide a standardized way for AI agents to discover and call them, so integrators do not need to build a custom client from scratch.

### Why this matters
This is powerful because it makes interoperability simple. You choose which functions to expose and how they are described, while AI agents can connect instantly without custom code. The result is faster adoption, broader compatibility, and a smoother experience across the ecosystem.
```

## Breaking Down PitchScoop

We decided to try an **MCP-first approach**: build every feature as an AI-callable tool first, then add REST endpoints as wrappers. We built this with **Python FAST API** following a strict **Domain Driven Design** principles. and a Typscript seperate repo frontend. 


```mermaid
graph TD
    A[AI Assistant] --> B[MCP Tools]
    C[Web Frontend] --> D[REST APIs]
    
    B --> E[Domain Routers]
    D --> E
    
    E --> F[Events Domain]
    E --> G[Recordings Domain]
    E --> H[Scoring Domain] 
    E --> I[Leaderboards Domain]
    E --> J[Users Domain]
    
    F --> F1[events.create_event]
    F --> F2[events.join_event]
    G --> G1[pitches.start_recording]
    G --> G2[pitches.get_transcript]
    H --> H1[analysis.score_pitch]
    H --> H2[analysis.generate_feedback]
    I --> I1[leaderboard.get_rankings]
    I --> I2[leaderboard.update_scores]
    J --> J1[users.create_user]
    J --> J2[users.set_role]
```

**Result**: We ended up with 32+ MCP tools organized into 5 domains. Each domain has its own router, models, and business logic. This approach let us quickly test AI-assisted event management while still providing traditional web interfaces.

### Mid-Morning: Organizing with Domain-Driven Design

To keep things manageable in a time crunch, we organized the codebase by domain. Each domain became self-contained:

```python
# Clean domain structure
api/domains/
â”œâ”€â”€ events/
â”‚   â”œâ”€â”€ router.py          # REST endpoints (/api/events/*)
â”‚   â”œâ”€â”€ mcp/               # MCP tools (events.*)
â”‚   â””â”€â”€ models.py          # Pydantic models
â”œâ”€â”€ recordings/
â”‚   â”œâ”€â”€ router.py          # REST endpoints (/api/sessions/*)
â”‚   â”œâ”€â”€ mcp/               # MCP tools (pitches.*)
â”‚   â””â”€â”€ value_objects/     # Domain objects
â”œâ”€â”€ scoring/
â”‚   â”œâ”€â”€ router.py          # REST endpoints (/api/analysis/*)
â”‚   â””â”€â”€ mcp/               # MCP tools (analysis.*)
â”œâ”€â”€ leaderboards/
â”‚   â”œâ”€â”€ router.py          # REST endpoints (/api/leaderboard/*)
â”‚   â””â”€â”€ mcp/               # MCP tools (leaderboard.*)
â”œâ”€â”€ users/
â”‚   â”œâ”€â”€ router.py          # REST endpoints (/api/users/*, /api/auth/*)
â”‚   â””â”€â”€ mcp/               # MCP tools (users.*)
â””â”€â”€ shared/
    â””â”€â”€ models.py          # Cross-domain models
```

**What we learned**: This structure helped us move faster during the hackathon. Each person could focus on a specific domain without stepping on each other's toes, and new features stayed contained to their relevant domain.

## Afternoon: Redis Stack as Our Single Data Platform

With only 7 hours to build and demo, we needed to minimize infrastructure complexity. Redis Stack 7.2 let us handle multiple data needs with one platform:

```mermaid
graph TB
    A[FastAPI Application] --> B[Redis Stack 7.2]
    B --> C[Session Storage]
    B --> D[Real-time Caching]
    B --> E[Vector Search Engine]
    B --> F[Document Indexing]
    
    C --> C1[User Sessions]
    C --> C2[Recording States]
    C --> C3[Competition Data]
    
    D --> D1[Transcript Segments]
    D --> D2[Audio Metadata]
    D --> D3[Scoring Cache]
    
    E --> E1[Semantic Search]
    E --> E2[RAG Queries]
    E --> E3[Content Similarity]
    
    F --> F1[Event Documents]
    F --> F2[Pitch Analysis]
    F --> F3[Market Research]
```

| Feature | Implementation | Use Case |
|---------|----------------|----------|
| **Session Management** | Redis Hash + TTL | User authentication, recording sessions |
| **Real-time Caching** | Redis Strings/Lists | Transcript segments, leaderboard data |
| **Vector Search** | RediSearch + VSS | Semantic document search, content similarity |
| **Document Indexing** | RedisVL + LlamaIndex | RAG-powered pitch analysis and feedback |
| **Pub/Sub Messaging** | Redis Streams | Real-time updates, WebSocket broadcasting |
| **Leaderboard Rankings** | Redis Sorted Sets | Live competition rankings with scores |

## Redis Patterns We Used

Here are some examples of how we used different Redis data structures. Each one solved a specific challenge we faced:

```python
import json
import redis.asyncio as redis
from datetime import datetime, timedelta

class PitchScoopRedisService:
    def __init__(self):
        self.redis_client = redis.from_url(
            "redis://localhost:6379/0", decode_responses=True
        )
    
    async def create_event(self, event_id: str, event_data: dict):
        """Store event data with expiration using Redis Strings"""
        await self.redis_client.setex(
            f"event:{event_id}",
            86400 * 30,  # 30 days TTL
            json.dumps(event_data)
        )
        
        # Initialize related data structures
        await self.redis_client.setex(
            f"event:{event_id}:participants", 86400 * 30, json.dumps([])
        )
    
    async def add_participant(self, event_id: str, participant_data: dict):
        """Add participant using Redis Lists for ordered data"""
        # Add to participant list
        await self.redis_client.lpush(
            f"event:{event_id}:participants", 
            json.dumps(participant_data)
        )
        
        # Update participant count using Redis Hash
        await self.redis_client.hincrby(
            f"event:{event_id}:stats", "participant_count", 1
        )
    
    async def update_live_leaderboard(self, event_id: str, 
                                      team_name: str, score: float):
        """Real-time leaderboard using Redis Sorted Sets"""
        # Update team score (automatically sorts by score)
        await self.redis_client.zadd(
            f"event:{event_id}:leaderboard",
            {team_name: score}
        )
        
        # Set expiration for cleanup
        await self.redis_client.expire(
            f"event:{event_id}:leaderboard", 86400 * 7
        )
    
    async def get_top_teams(self, event_id: str, limit: int = 10):
        """Get top teams from leaderboard (descending order)"""
        return await self.redis_client.zrevrange(
            f"event:{event_id}:leaderboard",
            0, limit - 1,
            withscores=True
        )
    
    async def cache_session_data(self, session_id: str, 
                                transcript_segments: list):
        """Cache real-time transcript data using Redis Hashes"""
        session_key = f"session:{session_id}"
        
        # Store metadata in hash
        await self.redis_client.hmset(session_key, {
            "status": "recording",
            "start_time": datetime.utcnow().isoformat(),
            "segment_count": len(transcript_segments),
            "last_updated": datetime.utcnow().isoformat()
        })
        
        # Store segments as separate keys for efficient retrieval
        for i, segment in enumerate(transcript_segments):
            await self.redis_client.setex(
                f"session:{session_id}:segment:{i}",
                3600,  # 1 hour TTL
                json.dumps(segment)
            )
    
    async def search_events_by_pattern(self, pattern: str = "event:*"):
        """Pattern-based key scanning for event discovery"""
        events = []
        async for key in self.redis_client.scan_iter(match=pattern):
            if not (":participants" in key or ":sessions" in key):
                event_data = await self.redis_client.get(key)
                if event_data:
                    events.append(json.loads(event_data))
        return events
    
    async def publish_live_update(self, event_id: str, update_data: dict):
        """Real-time updates using Redis Pub/Sub"""
        await self.redis_client.publish(
            f"event:{event_id}:updates",
            json.dumps({
                "timestamp": datetime.utcnow().isoformat(),
                "type": "leaderboard_update",
                "data": update_data
            })
        )
```

### Breaking Down the Redis Patterns

**1. Event Storage with TTL (Redis Strings)**
```python
await self.redis_client.setex(f"event:{event_id}", 86400 * 30, json.dumps(event_data))
```
Redis Strings with automatic expiration solve the "document storage with lifecycle" problem. Events automatically clean up after 30 days, preventing memory bloat without manual cleanup jobs.

**2. Ordered Participants (Redis Lists)**  
```python
await self.redis_client.lpush(f"event:{event_id}:participants", json.dumps(participant_data))
```
Redis Lists maintain insertion order and allow efficient head/tail operations. Perfect for "first registered" participant queues or chronological activity feeds.

**3. Live Leaderboards (Redis Sorted Sets)**
```python
await self.redis_client.zadd(f"event:{event_id}:leaderboard", {team_name: score})
```
This is Redis magicâ€”Sorted Sets automatically maintain ranking order. Update any team's score and the leaderboard instantly reflects the new rankings. No manual sorting needed.

**4. Session Metadata (Redis Hashes)**
```python
await self.redis_client.hmset(session_key, {
    "status": "recording", 
    "start_time": datetime.utcnow().isoformat()
})
```
Redis Hashes act like database rowsâ€”perfect for structured data that changes frequently. Individual fields can be updated without rewriting the entire object.

**5. Real-Time Updates (Redis Pub/Sub)**
```python
await self.redis_client.publish(f"event:{event_id}:updates", json.dumps(update_data))
```
Pub/Sub enables WebSocket-style real-time features without additional infrastructure. When a leaderboard changes, all connected clients instantly receive updates.

**6. Pattern-Based Discovery (Key Scanning)**
```python
async for key in self.redis_client.scan_iter(match="event:*"):
```
Redis key patterns enable flexible data discovery. Find all events, all sessions for an event, or all data for cleanupâ€”without maintaining separate indexes.

### Benefits of Using One Data Platform

Using Redis Stack for everything simplified our stack:
- âœ… No separate cache layer needed (Redis handles hot data)
- âœ… No message queue setup required (Redis Pub/Sub)
- âœ… No custom ranking algorithms (Sorted Sets handle it)
- âœ… Automatic cleanup with TTL (no manual jobs)
- âœ… Flexible data discovery with key patterns

For a hackathon prototype, this reduced complexity was exactly what we needed. Redis Stack + MCP proved to be a productive combination for rapid AI application development.

## Demo Time: Testing the Live Demo

During our demo, we wanted to show how MCP tools could work in practice. Here's how the interaction went:

**Audience**: *"Can you show the AI creating an event in real-time?"*

**Claude** (via MCP): *"Sure, let me create a demo event..."*

```bash
# MCP Tool Call #1: Create Event (0.3s)
await mcp_client.call_tool("events.create_event", {
    "event_type": "demo_day",
    "event_name": "TechStars Demo Day LIVE", 
    "max_participants": 50
})

# Result: Event "techstars-demo-live" created instantly
# Redis operations: 12 writes in 0.3s
```

*10 seconds pass... teams are registering via another terminal*

**Audience**: *"Can it show current standings?"*

```bash
# MCP Tool Call #2: Live Leaderboard (0.1s) 
await mcp_client.call_tool("leaderboard.get_rankings")

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LIVE LEADERBOARD - TechStars Demo Day          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¥‡ NeuralFlow AI      â”‚ 94.5 â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ â”‚
â”‚ ğŸ¥ˆ Quantum Commerce   â”‚ 92.1 â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘ â”‚
â”‚ ğŸ¥‰ VectorDB Labs      â”‚ 89.7 â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘ â”‚
â”‚ 4. AI Copilot Inc     â”‚ 87.3 â”‚ â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘ â”‚
â”‚ 5. Redis Robotics     â”‚ 85.9 â”‚ â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Teams Pitched: 18/50  â”‚  Live Updates: ON       â”‚
â”‚ Avg Processing: 0.8s  â”‚  Redis Ops/sec: 847    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Audience**: *"Is this processing real data in real-time?"*

**Us**: *"Yes, here's a live update..."* [types in another terminal]

```bash
# Someone submits a new pitch in parallel...
# The leaderboard updates INSTANTLY:

ğŸ”´ LIVE UPDATE: "DeepMind Ventures" just scored 95.2! 
   NEW LEADER! ğŸš€
```

**Audience**: *"Can it analyze the top team?"*

```bash
# MCP Tool Call #3: AI Analysis (1.2s)
await mcp_client.call_tool("analysis.get_scoring_results", {
    "team": "DeepMind Ventures"
})

ğŸ“Š AI PITCH ANALYSIS - DeepMind Ventures
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’ª STRENGTHS:
  âœ“ Revolutionary use of Redis Vector Search for ML inference
  âœ“ 10x faster than competitors (benchmarked live)
  âœ“ Clear $50M market opportunity

âš ï¸ WATCH POINTS:  
  â€¢ Needs enterprise security roadmap
  â€¢ Scale testing beyond 10K users

ğŸ¯ VERDICT: "Best technical execution we've seen.
            Investment committee should fast-track."

â±ï¸ Analysis time: 1.2 seconds
ğŸ’¾ Powered by: Redis AI + GPT-4 + MCP
```

### What Made This Different

**Audience**: *"How is the AI able to do this directly?"*

**Traditional Approach:**
```python
# Typical API integration
try:
    headers = {"Authorization": f"Bearer {get_token()}"}
    response = requests.post(
        "https://api.pitchscoop.com/v1/events",
        json=event_data,
        headers=headers,
        timeout=30
    )
    if response.status_code == 200:
        event = response.json()
        # More error handling, retries, parsing...
except RequestException as e:
    # Handle network errors, retry logic...
```

**MCP Approach:**
```python
# Direct tool call
await mcp.call_tool("create_event", params)
```

**Audience**: *"So the AI calls your functions directly?"*

**Us**: *"Exactly. MCP treats your business logic as native AI tools instead of external API calls."*

The key difference: instead of the AI making HTTP requests, it calls functions directly through the MCP protocol.

## End of Day: The Results

After a full day at the AWS GenAI Loft in San Francisco, we had a working demonstration that helped us learn a lot about MCP and Redis Stack.

### What We Built

âœ… **32+ MCP Tools** - Core features exposed as AI-callable functions  
âœ… **Fast responses** - Sub-second performance via Redis Stack  
âœ… **Working demo** - AI could manage events and scoring in real-time  
âœ… **Stable platform** - Handled concurrent operations during demo

### Project Stats

```bash
Hackathon Project Metrics - MCP AI Agents Hackathon (Sep 19)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Location:         AWS GenAI Loft, San Francisco
MCP Tools:        32+ AI-callable functions
Domains:          5 (events, recordings, scoring, leaderboards, users)
Redis Features:   6 data types (strings, lists, sets, hashes, pub/sub, vectors)
Team Size:        Small team

Demo Performance:
  â€¢ Vector Search:  < 50ms
  â€¢ Leaderboards:   < 10ms  
  â€¢ AI Analysis:    ~ 1.2s
  â€¢ Audio Process:  ~ 0.8s

Result: Working prototype with valuable MCP + Redis learnings
```

## Key Learnings: MCP + Redis Stack

### Why MCP Worked Well
```python
# Traditional approach:
class APIHandler:
    def __init__(self):
        self.auth = AuthenticationLayer()
        self.validation = RequestValidator()
        self.serializer = ResponseSerializer()
        # More infrastructure...

# MCP approach:
class MCPTool:
    async def run(self, params):
        return await business_logic(params)  # Focus on the logic
```

### Why Redis Stack Worked Well
```yaml
Typical Stack:             Our Stack:
- PostgreSQL (database)    â†’ Redis (unified platform)
- ElasticSearch (search)   â†’ RediSearch
- RabbitMQ (queues)        â†’ Redis Streams  
- Memcached (cache)        â†’ Redis Cache
- Vector DB (similarity)   â†’ Redis Vector Search

5 separate systems â†’ 1 integrated platform
```

## Try It Yourself

If you want to experiment with MCP and Redis Stack:

```bash
# Clone the project
git clone https://github.com/yourusername/pitchscoop
cd pitchscoop

# Quick setup
./setup.sh  # Docker + Redis + MCP ready

# Test with an AI assistant
"Hey Claude, create a demo pitch competition"
# Claude uses the MCP tools to interact with your backend
```

### What's Included

ğŸš€ **MCP Tools** - Examples of AI-callable business functions  
âš¡ **Redis Examples** - Different data structures in action  
ğŸ“ **Domain Structure** - Clean architecture patterns  
ğŸ“¦ **Open Source** - Learn, modify, and adapt

## What We Learned

**Traditional approach**: AI â†’ HTTP API â†’ Your App  
**MCP approach**: AI â†’ Direct Tool Calls â†’ Your App  

**Typical stack**: Multiple databases + integration complexity  
**Redis Stack**: Unified platform + simpler operations  

In one intense day, we built a working prototype that taught us a lot about these technologies. While it's not production-ready, it demonstrates the potential of combining MCP with Redis Stack for AI applications.

## Resources

ğŸ”— **Code**: [github.com/yourusername/pitchscoop](https://github.com/yourusername/pitchscoop)  
ğŸ“š **MCP Documentation**: [modelcontextprotocol.io](https://modelcontextprotocol.io)  
ğŸ”´ **Redis Stack**: [redis.io/try-free](https://redis.io/try-free)  
ğŸ“¦ **Domain Architecture Guide**: See our `DOMAIN_STRUCTURE.md` for implementation details  

---

**MCP and Redis Stack make a powerful combination for AI application development.** If you're building AI-integrated applications, consider this approach for rapid prototyping.

Built at the [MCP - AI Agents Hackathon](https://juniper-giant-a3f.notion.site/MCP-AI-Agents-Hackathon-Sep-19-11c9fb250b4b80c488b7e2d7b6d6816d) (Sep 19, 2024) at AWS GenAI Loft, San Francisco

Questions about the implementation?  
Feel free to explore the code or reach out: [@yourhandle](https://twitter.com/yourhandle)


------ 














# Why MCP + Redis Stack is the Perfect Combo for AI Applications

*Building PitchScoop: A real-world case study in MCP-first architecture with Redis vector search*

## The Challenge: Making AI Assistants Truly Useful

AI assistants are powerful, but they often feel disconnected from real applications. They can chat, generate text, and answer questionsâ€”but can they actually *do* things in your systems? That's where **Model Context Protocol (MCP)** changes everything.

At PitchScoop, we built an AI-powered pitch competition platform that demonstrates how MCP + Redis Stack creates a seamless bridge between AI assistants and production applications.

## MCP-First Architecture: Every Feature is a Tool

Instead of building a traditional web API and hoping AI assistants could somehow use it, we flipped the approach: **every business function is exposed as a standardized MCP tool**.

```mermaid
graph TD
    A[AI Assistant] --> B[MCP Protocol Layer]
    B --> C[Domain Router]
    C --> D[Events Domain]
    C --> E[Recordings Domain] 
    C --> F[Scoring Domain]
    C --> G[Leaderboards Domain]
    C --> H[Users Domain]
    
    D --> D1[Create Events]
    D --> D2[Manage Participants]
    E --> E1[Audio Recording]
    E --> E2[Speech-to-Text]
    F --> F1[AI Analysis]
    F --> F2[Multi-dimensional Scoring]
```

This means Claude, GPT, or any MCP-compatible AI can directly:
- Create and manage pitch competitions
- Start audio recordings and process speech-to-text
- Run AI-powered scoring analysis
- Generate live leaderboards
- Provide personalized feedback

All through **32 standardized MCP tools** that follow OpenAPI specifications.

## Redis Stack: The Multi-Purpose AI Data Platform

Here's where it gets interesting. Most AI applications struggle with data architectureâ€”you need caching, session management, vector search, and real-time capabilities. Instead of juggling multiple databases, we use **Redis Stack 7.2** for everything:

```mermaid
graph TB
    A[FastAPI Application] --> B[Redis Stack 7.2]
    B --> C[Session Storage]
    B --> D[Real-time Caching]
    B --> E[Vector Search Engine]
    B --> F[Document Indexing]
    
    C --> C1[User Sessions]
    C --> C2[Recording States]
    C --> C3[Competition Data]
    
    D --> D1[Transcript Segments]
    D --> D2[Audio Metadata]
    D --> D3[Scoring Cache]
    
    E --> E1[Semantic Search]
    E --> E2[RAG Queries]
    E --> E3[Content Similarity]
    
    F --> F1[Event Documents]
    F --> F2[Pitch Analysis]
    F --> F3[Market Research]
```

| Feature | Implementation | Use Case |
|---------|----------------|----------|
| **Session Management** | Redis Hash + TTL | User authentication, recording sessions |
| **Real-time Caching** | Redis Strings/Lists | Transcript segments, leaderboard data |
| **Vector Search** | RediSearch + VSS | Semantic document search, content similarity |
| **Document Indexing** | RedisVL + LlamaIndex | RAG-powered pitch analysis and feedback |
| **Pub/Sub Messaging** | Redis Streams | Real-time updates, WebSocket broadcasting |
| **Leaderboard Rankings** | Redis Sorted Sets | Live competition rankings with scores |

## Real-World Code: Multi-Purpose Redis Operations

Here's how PitchScoop uses Redis Stack's diverse capabilities. Each method demonstrates a different Redis data structure solving a specific business problem:

```python
import json
import redis.asyncio as redis
from datetime import datetime, timedelta

class PitchScoopRedisService:
    def __init__(self):
        self.redis_client = redis.from_url(
            "redis://localhost:6379/0", decode_responses=True
        )
    
    async def create_event(self, event_id: str, event_data: dict):
        """Store event data with expiration using Redis Strings"""
        await self.redis_client.setex(
            f"event:{event_id}",
            86400 * 30,  # 30 days TTL
            json.dumps(event_data)
        )
        
        # Initialize related data structures
        await self.redis_client.setex(
            f"event:{event_id}:participants", 86400 * 30, json.dumps([])
        )
    
    async def add_participant(self, event_id: str, participant_data: dict):
        """Add participant using Redis Lists for ordered data"""
        # Add to participant list
        await self.redis_client.lpush(
            f"event:{event_id}:participants", 
            json.dumps(participant_data)
        )
        
        # Update participant count using Redis Hash
        await self.redis_client.hincrby(
            f"event:{event_id}:stats", "participant_count", 1
        )
    
    async def update_live_leaderboard(self, event_id: str, 
                                      team_name: str, score: float):
        """Real-time leaderboard using Redis Sorted Sets"""
        # Update team score (automatically sorts by score)
        await self.redis_client.zadd(
            f"event:{event_id}:leaderboard",
            {team_name: score}
        )
        
        # Set expiration for cleanup
        await self.redis_client.expire(
            f"event:{event_id}:leaderboard", 86400 * 7
        )
    
    async def get_top_teams(self, event_id: str, limit: int = 10):
        """Get top teams from leaderboard (descending order)"""
        return await self.redis_client.zrevrange(
            f"event:{event_id}:leaderboard",
            0, limit - 1,
            withscores=True
        )
    
    async def cache_session_data(self, session_id: str, 
                                transcript_segments: list):
        """Cache real-time transcript data using Redis Hashes"""
        session_key = f"session:{session_id}"
        
        # Store metadata in hash
        await self.redis_client.hmset(session_key, {
            "status": "recording",
            "start_time": datetime.utcnow().isoformat(),
            "segment_count": len(transcript_segments),
            "last_updated": datetime.utcnow().isoformat()
        })
        
        # Store segments as separate keys for efficient retrieval
        for i, segment in enumerate(transcript_segments):
            await self.redis_client.setex(
                f"session:{session_id}:segment:{i}",
                3600,  # 1 hour TTL
                json.dumps(segment)
            )
    
    async def search_events_by_pattern(self, pattern: str = "event:*"):
        """Pattern-based key scanning for event discovery"""
        events = []
        async for key in self.redis_client.scan_iter(match=pattern):
            if not (":participants" in key or ":sessions" in key):
                event_data = await self.redis_client.get(key)
                if event_data:
                    events.append(json.loads(event_data))
        return events
    
    async def publish_live_update(self, event_id: str, update_data: dict):
        """Real-time updates using Redis Pub/Sub"""
        await self.redis_client.publish(
            f"event:{event_id}:updates",
            json.dumps({
                "timestamp": datetime.utcnow().isoformat(),
                "type": "leaderboard_update",
                "data": update_data
            })
        )
```

### Breaking Down the Redis Patterns

**1. Event Storage with TTL (Redis Strings)**
```python
await self.redis_client.setex(f"event:{event_id}", 86400 * 30, json.dumps(event_data))
```
Redis Strings with automatic expiration solve the "document storage with lifecycle" problem. Events automatically clean up after 30 days, preventing memory bloat without manual cleanup jobs.

**2. Ordered Participants (Redis Lists)**  
```python
await self.redis_client.lpush(f"event:{event_id}:participants", json.dumps(participant_data))
```
Redis Lists maintain insertion order and allow efficient head/tail operations. Perfect for "first registered" participant queues or chronological activity feeds.

**3. Live Leaderboards (Redis Sorted Sets)**
```python
await self.redis_client.zadd(f"event:{event_id}:leaderboard", {team_name: score})
```
This is Redis magicâ€”Sorted Sets automatically maintain ranking order. Update any team's score and the leaderboard instantly reflects the new rankings. No manual sorting needed.

**4. Session Metadata (Redis Hashes)**
```python
await self.redis_client.hmset(session_key, {
    "status": "recording", 
    "start_time": datetime.utcnow().isoformat()
})
```
Redis Hashes act like database rowsâ€”perfect for structured data that changes frequently. Individual fields can be updated without rewriting the entire object.

**5. Real-Time Updates (Redis Pub/Sub)**
```python
await self.redis_client.publish(f"event:{event_id}:updates", json.dumps(update_data))
```
Pub/Sub enables WebSocket-style real-time features without additional infrastructure. When a leaderboard changes, all connected clients instantly receive updates.

**6. Pattern-Based Discovery (Key Scanning)**
```python
async for key in self.redis_client.scan_iter(match="event:*"):
```
Redis key patterns enable flexible data discovery. Find all events, all sessions for an event, or all data for cleanupâ€”without maintaining separate indexes.

### The Power of Single-Platform Architecture

Notice what this code **doesn't** need:
- âŒ No separate cache layer (Redis handles hot data)
- âŒ No message queue system (Redis Pub/Sub)
- âŒ No ranking algorithms (Sorted Sets handle it)
- âŒ No manual cleanup jobs (TTL expires data automatically)
- âŒ No complex indexing strategy (Key patterns work beautifully)

This is why Redis Stack + MCP works so well for AI applications. You get enterprise-grade performance and features with dramatically reduced complexity.

## AI in Action: A Real Conversation

Here's how an AI assistant actually interacts with PitchScoop using MCP tools. This is a real conversation flow:

**Human**: *"Help me set up a hackathon competition for 20 teams, then show me the current standings after some pitches come in."*

**Claude**: *"I'll help you set up a hackathon and monitor the competition. Let me start by creating the event."*

```python
# Claude calls MCP tool directly
result = await mcp_client.call_tool("events.create_event", {
    "event_type": "hackathon",
    "event_name": "AI Innovation Challenge 2024", 
    "description": "Build AI applications using MCP tools",
    "max_participants": 20,
    "duration_minutes": 5
})

# Returns: {
#   "event_id": "mcp-hackathon",
#   "status": "active",
#   "max_participants": 20,
#   "instructions": {
#     "next_step": "Add participants with events.join_event"
#   }
# }
```

**Claude**: *"Perfect! I've created 'AI Innovation Challenge 2024' with event ID `mcp-hackathon`. The competition is now active and ready for participants. Let me check if any teams have joined and pitched yet."*

```python
# Check current leaderboard
leaderboard = await mcp_client.call_tool("leaderboard.get_rankings", {
    "event_id": "mcp-hackathon",
    "limit": 10,
    "include_details": True
})

# Returns live rankings with scores
# {
#   "leaderboard": [
#     {
#       "rank": 1,
#       "team_name": "Vector Innovators", 
#       "total_score": 87.5,
#       "pitch_title": "Smart Contract Analyzer",
#       "category_scores": {
#         "idea_score": 22.0,
#         "technical_score": 20.5,
#         "tool_use_score": 23.0,
#         "presentation_score": 22.0
#       }
#     },
#     {
#       "rank": 2, 
#       "team_name": "AI Architects",
#       "total_score": 84.2,
#       "pitch_title": "Automated Code Review Bot"
#     }
#   ],
#   "total_teams": 8
# }
```

**Claude**: *"Great progress! Here are the current standings:*

*ğŸ† **Current Leaderboard** (8 teams have pitched so far):*

*1. **Vector Innovators** - 87.5 points*  
   *"Smart Contract Analyzer" - Strong across all categories*

*2. **AI Architects** - 84.2 points*  
   *"Automated Code Review Bot" - Solid technical implementation*

*The competition is heating up! Would you like me to analyze the pitch data or set up real-time notifications for new submissions?"*

```python
# Human asks for detailed analysis of top pitch
# Claude can instantly access the full scoring breakdown
analysis = await mcp_client.call_tool("analysis.get_scoring_results", {
    "session_id": "session_vector_innovators_001"
})

# Returns comprehensive AI analysis:
# {
#   "detailed_feedback": {
#     "strengths": [
#       "Innovative use of vector databases for smart contract analysis",
#       "Clear demonstration of MCP tool integration",
#       "Strong technical architecture with Redis vector search"
#     ],
#     "improvements": [
#       "Could expand on market size and competitive advantage", 
#       "Demo could show more complex contract scenarios"
#     ],
#     "judge_recommendation": "Excellent foundation with clear market focus..."
#   }
# }
```

### What Makes This Powerful

**Traditional API Integration:**
```python
# Multiple HTTP calls, manual data parsing, no standardization
response1 = requests.post("/api/events", json=event_data)
event_id = response1.json()["event_id"] 

response2 = requests.get(f"/api/events/{event_id}/leaderboard")
leaderboard = response2.json()

# Handle authentication, error codes, pagination, rate limits...
```

**MCP Integration:**
```python
# Direct tool calls, standardized interface, native AI integration
event = await mcp_client.call_tool("events.create_event", event_params)
leaderboard = await mcp_client.call_tool("leaderboard.get_rankings", {"event_id": event["event_id"]})

# AI assistant handles this natively - no HTTP complexity
```

The AI assistant treats PitchScoop operations as **native capabilities**, not external API calls. This is the fundamental shift MCP enables.

## The Results: AI That Actually Works

This architecture delivers measurable benefits:

- **< 50ms vector search latency** for 10k+ documents
- **32 MCP tools** accessible to any AI assistant
- **1000+ concurrent queries/second** on standard Redis Stack
- **Real-time updates** across all competition features
- **Seamless scaling** with Redis cluster for production

## Why This Matters

Most AI applications are demos. They look impressive but don't integrate with real business processes. MCP + Redis Stack changes that:

1. **MCP makes AI integration native** - not an afterthought
2. **Redis Stack handles all data needs** - no complex architecture 
3. **Vector search enables intelligent features** - semantic analysis, RAG, content similarity
4. **Real-time capabilities** keep AI responses current and relevant

## Try It Yourself

Want to see this in action? The PitchScoop platform is open source and demonstrates production-ready MCP integration:

```bash
git clone <repository-url>
cd pitchscoop  
./setup.sh  # One-command setup
```

Within 2 minutes, you'll have:
- 32 MCP tools running locally
- Redis Stack with vector search
- Real-time audio processing
- AI-powered scoring system

**Key URLs:**
- **API Documentation**: http://localhost:8000/docs  
- **RedisInsight Dashboard**: http://localhost:8001

The future of AI applications isn't just better modelsâ€”it's better integration. MCP + Redis Stack shows how to build AI systems that actually work in the real world.

---

*PitchScoop is an open-source MCP-first platform for AI-assisted pitch competitions. Built with FastAPI, Redis Stack, and Azure OpenAI, it demonstrates production-ready patterns for MCP integration.* s